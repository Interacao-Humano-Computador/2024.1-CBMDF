<!-- precisa conter de preferencia: 
1 - os objetivos, 
2 escopos, 
3 métodos(quais tipo de entrevistas etc.), 
4 como será selecionado os participantes, 
5 preparação para as entrevistas, 
6 os problemas encontrados(como lidar com isso),
7 feedback do usuário, 
8 interpretação de dados colhido(como será essa interpretação) , 
9 as possiveis melhorias e correções a serem feitas.

^^ lembrando que isso é um planejamento então significa que será como nós iremos lidar com esses dados, antes de, de fato obtê-los. -->

## Introdução
O planejamento é uma maneira de organizar passos que serão dados no futuros. Seja em se tratando de um projeto, uma tarefa, etc. Ele é intrínseco para o ordenamento adequado das ações para se chegar no objetivo. Sendo assim, dentro do escopo do planejamento do relato dos resultados, será utilizado como base o [planejamento da avaliação](../story_board/planejamento_avaliacao.md). Será descrito elementos seguintes como descritos na metodologia abaixo:

## Metodologia 
A metodologia seguirá o que Barbosa e Silva (1) propuseram. Os principais elementos a serem evidenciados serão:

1. Objetivos e Escopos;<br>
2. Métodos;<br>
3. Seleção de participantes;<br>
4. Descrição de erros;<br>
5. Feedback do usuário (dados coletados);<br>
6. Interpretação de dados;<br>
7. Melhorias e Correções para Reprojeto. <br>

## Tópicos
Os tópicos, já mencionados acima, serão especificados logo abaixo:

### Objetivo e escopo
Nesse tópico, será necessário que o avaliador descreva qual é o objetivo a ser alcançado com a avaliação do StoryBoard. Pode ser desde avaliar se o storyboard corresponde com o fluxo de tarefas e a funcionalidade em si, até se o StoryBoard corresponde com a realidade.

### Métodos 
O método escolhido para a avaliação de StoryBoards foi o de Insvestigação por entrevistas (2). Esse método consiste no avaliador fazer perguntas para o avaliado acerca de um tema a fim de captar resultados.<br>
Além disso, o avaliador precisa do acesso, saber fazer interpretações, obter opiniões, entender comportamento e expectativas acerca dos usuários sobre o sistema interativo (4), que no caso desse projeto serão os [storyboards](storyboards.md) executados pelos membros do grupo. 
<br><br>

O método escolhido para a avaliação de StoryBoards foi o de Insvestigação por entrevistas (2). Esse método consiste no avaliador fazer perguntas para o avaliado acerca de um tema a fim de captar resultados.<br>
Além disso, o avaliador precisa do acesso, saber fazer interpretações, obter opiniões, entender comportamento e expectativas acerca dos usuários sobre o sistema interativo (4), que no caso desse projeto serão os [storyboards](storyboards.md) executados pelos membros do grupo. 
<br><br>

No contexto dessa etapa do projeto da disciplina, os responsáveis pelos relatos dos resultados serão encarregados de fazer também as entrevistas. Para cada uma das entrevistas, será selecionada uma das funcionalidades analisadas na <a href="https://interacao-humano-computador.github.io/2024.1-CBMERJ/analise_requisitos_1/analise_tarefas/">análise de tarefas</a>.

#### Cronograma de entrevistas
Considerando que serão realizadas várias entrevistas para validar os storyboards, apresentamos o cronograma detalhado na Tabela 1, logo abaixo:

<center>

|    Entrevistador(es)   | Entrevistado(s)   | Horário do Início  |  Horário do Fim  |  Data   |    Tarefa    |      Local     |
| :--------------------: | :---------------: | :----------------: | :--------------: | :-----: | :----------: | :------------: |
| [Mariana Letícia](https://github.com/Marianannn) |     A decidir     |      a decidir      |     a decidir      |     a decidir      |   Solicitar declaração de registro de ocorrência   | a decidir |
| [Daniela Alarcão](https://github.com/danialarcao) |     A decidir     |      a decidir      |     a decidir      |     a decidir      |      | a decidir |
| [Bruna Lima](https://github.com/libruna) | A decidir | 14:50 | 15:20 |  29/05/2024  |  Solicitação de Ficha de Atendimento | FGA |
| [Mariana Letícia](https://github.com/Marianannn) |     A decidir     |      a decidir      |     a decidir      |     a decidir      |      | a decidir |
| [Daniela Alarcão](https://github.com/danialarcao) |     A decidir     |      a decidir      |     a decidir      |     a decidir      |      | a decidir |
| [Bruna Lima](https://github.com/libruna) | A decidir | 15:30 | 16:00 | 29/05/2024 | A decidir | FGA |

<p style="text-align: center">Tabela 1: Cronograma planejado de entrevistas</p>
<p style="text-align: center">Fonte: Mariana Letícia</p>

</center>

- Modelo do cronograma:

Será necessário também, no relato de resultados, que haja um cronograma Executado sobre o que de fato aconteceu. Segue abaixo um modelo que deverá ser seguido quando se preencher esses dados na tabela 2:

<center>

|                  Entrevistadores                     | Entrevistados   | Horário do Início | Horário do Fim |         Data   |           Tarefa            |           Local            |
| :--------------------------------------------------: | :-------------: | :---------------: | :------------: | :----------------: | :-------------------------: | :------------------------: |
||||||||

<p style="text-align: center">Tabela 2: Modelo de cronograma executado de entrevistas</p>
<p style="text-align: center">Fonte: Mariana Letícia</p>

</center>


### Seleção de participantes
A seleção de participantes terá como base o <a href="https://interacao-humano-computador.github.io/2024.1-CBMERJ/analise_requisitos_1/perfil_usuario/">perfil do usuário</a> e as <a href="https://interacao-humano-computador.github.io/2024.1-CBMERJ/analise_requisitos_1/personas/">personas</a>. Para cada funcionalidade apresentada no storyboard, será selecionado um participante, totalizando assim seis participantes. Além disso, cada entrevistado será apresentado ao termo de consentimento, e prosseguiremos com as entrevistas somente se os termos forem aceitos pelo participante.

### Descrição de erros
Durante a descrição de erros e problemas encontrados, o avaliador necessitará de informar: onde ocorreu este erro; uma descrição e uma explicação para o problema ter ocorrido; levantar quais quesitos de usabilidade foram afetados nesse problema; e sugestões de possíveis soluções. (3)

### Feedback do usuário
Durante as entrevistas, é importante que o entrevistador crie um ambiente acolhedor para que os participantes se sintam à vontade para expressar suas opiniões e experiências sobre os storyboards avaliados. Uma postura receptiva e atenta do entrevistador é essencial para incentivar os participantes a compartilhar feedback honesto e construtivo.

### Interpretação dos dados
Nesta etapa, os dados coletados dos participantes serão analisados individualmente para buscar respostas aos objetivos estabelecidos previamente no [planejamento da avaliação](../story_board/planejamento_avaliacao.md). Essa análise será conduzida manualmente, utilizando as anotações feitas durante a avaliação e, se necessário, revisando os vídeos das entrevistas, com o propósito de atribuir significado aos dados.

### Consolidação dos dados
Após a interpretação dos dados, é fundamental conduzir uma análise conjunta visando identificar padrões e recorrências nos resultados. Essas recorrências nos auxiliam a distinguir entre características compartilhadas pelo grupo e características individuais. Durante este processo, revisamos as perguntas das entrevistas para responder a cada uma delas ou justificar a ausência de respostas.

### Reprojeto
Os avaliadores devem oferecer propostas de soluções para os problemas e sugestões de melhoria identificados durante a avaliação, destinadas a serem implementadas no reprojeto. Essa etapa visa garantir que os problemas sejam abordados de maneira eficaz e que as melhorias sugeridas sejam implementadas para otimizar a experiência do usuário.


## Referências Bibliográficas
> 1. Dinis, S., & Santana, B. (2021). Interação Humano-Computador (1ª ed.). [Capítulo 11.7.5, p. 279]
> 2. Dinis, S., & Santana, B. (2021). Interação Humano-Computador (1ª ed.). [Capítulo 11.6, p. 272]
> 3. Dinis, S., & Santana, B. (2021). Interação Humano-Computador (1ª ed.). [Capítulo 12.2, p. 303]
> 4. QUEIROZ, João. Métodos de Avaliação de IHC. IFRN. Disponível em: https://docente.ifrn.edu.br/joaoqueiroz/disciplinas/ihc-interacao-humano-computador/aulas/aula-9. Acesso em: 20 maio 2024.

## Bibliografia
> 1. IRLABR. Apostila de IHC: Usabilidade e suas metas. Disponível em: <https://irlabr.wordpress.com/apostila-de-ihc/6-usabilidade-e-suas-metas/#:~:text=As%20metas%20de%20usabilidade%20tratam,para%20o%20desenvolvimento%20do%20projeto>. Acesso em: 11 de maio de 2024.
> 2. Barbosa, S. D. J.; Silva, B. S. da; Silveira, M. S.; Gasparini, I.; Darin, T.; Barbosa, G. D. J. Interação Humano-Computador e Experiência do usuário. (2021). Acesso em: 17 de maio de 2024.

## Histórico de Versões

| Versão |    Data    | Descrição                                 | Autor(es)                                       | Revisor(es)                                    |
| ------ | :--------: | ----------------------------------------- | ----------------------------------------------- | ---------------------------------------------- |
| `1.0`   | 16/05/2024 | Criação da página                         | [Mariana Letícia](https://github.com/Marianannn) |     |
| `2.0`   | 17/05/2024 | Adição da introdução dos relatos de resultados                         | [Mariana Letícia](https://github.com/Marianannn) |     |
| `3.0`   | 17/05/2024 | Adição dos tópicos: objetivo e escopo; métodos; seleção de participantes; e descrição de erros                         | [Mariana Letícia](https://github.com/Marianannn) |     |
| `3.1`   | 20/05/2024 | Alteraçõ do método de avaliação de IHC                         | [Mariana Letícia](https://github.com/Marianannn) |     |
| `4.0`  | 21/05/2024 | Adição dos tópicos de feedback, interpretação, consolidação e reprojeto | [Bruna Lima](https://github.com/libruna) |     |
